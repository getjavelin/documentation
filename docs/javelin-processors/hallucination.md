# Hallucination Detection

Hallucination detection in Javelin identifies when AI models generate factually incorrect or nonsensical responses that appear plausible but lack grounding in reality. This processor analyzes LLM outputs and provides probability scores indicating the likelihood of hallucinated content. You'll learn to configure hallucination detection thresholds, integrate scoring into your application logic, and set up automated responses to reduce the impact of AI hallucinations on your users. 

For more information on how to enable hallucination detection, refer to the [Javelin Processors documentation](processors-overview).
