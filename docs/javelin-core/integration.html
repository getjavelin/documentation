<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-javelin-core/integration" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">Applications | Javelin</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://getjavelin.io/docs/javelin-core/integration"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Applications | Javelin"><meta data-rh="true" name="description" content="Its easy to integrate applications that leverage LLMs with Javelin. We have made it easy to seamlessly connect your applications to route all LLM traffic through Javelin with minimal code changes."><meta data-rh="true" property="og:description" content="Its easy to integrate applications that leverage LLMs with Javelin. We have made it easy to seamlessly connect your applications to route all LLM traffic through Javelin with minimal code changes."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://getjavelin.io/docs/javelin-core/integration"><link data-rh="true" rel="alternate" href="https://getjavelin.io/docs/javelin-core/integration" hreflang="en"><link data-rh="true" rel="alternate" href="https://getjavelin.io/docs/javelin-core/integration" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.6c1f1e17.css">
<script src="/assets/js/runtime~main.53b8a505.js" defer="defer"></script>
<script src="/assets/js/main.2b9f8ede.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/javelinlogo.png" alt="Javelin Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/javelinlogo.png" alt="Javelin Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate"></b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/javelin-core/overview">Getting Started</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/javelin-processors/overview">Guardrails</a><a class="navbar__item navbar__link" href="/api">API Reference</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/javelin-python/quickstart">Python SDK</a></div><div class="navbar__items navbar__items--right"><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/javelin-core/overview">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/javelin-core/integration">Integrating Applications</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/javelin-core/integration">Applications</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/javelin-webapp/threat-alerts/overview">Features</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/javelin-processors/overview">Guardrails Processors</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/javelin-core/playground/overview">Playground</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/javelin-python/quickstart">Python SDK</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/security">Security</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/changelog">Changelog</a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Integrating Applications</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Applications</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Applications</h1></header>
<p>Its easy to integrate applications that leverage LLMs with Javelin. We have made it easy to seamlessly connect your applications to route all LLM traffic through Javelin with minimal code changes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="leveraging-the-javelin-platform">Leveraging the Javelin Platform<a href="#leveraging-the-javelin-platform" class="hash-link" aria-label="Direct link to Leveraging the Javelin Platform" title="Direct link to Leveraging the Javelin Platform">​</a></h2>
<p>The core usage of Javelin is to define routes, and then to define what to do at each route. Rather than having your LLM Applications (like Co-Pilot apps etc.,) individually &amp; directly point to the LLM Vendor &amp; Model (like OpenAI, Gemini etc.,), configure the provider/model endpoint to be your Javelin endpoint. This ensures that all applications that leverage AI Models will route their requests through the gateway. Javelin supports all the <a href="/docs/javelin-core/supported-llms">latest models and providers</a>, so you don&#x27;t have to make any changes to your application or how requests to models are sent.</p>
<p>See <a href="/docs/javelin-core/routeconfiguration">Javelin Configuration</a> section, for details on how to setup routes on the gateway to different models and providers.</p>
<p>See <a href="/docs/javelin-python/quickstart">Python SDK</a> for details on how you can easily embed this within your AI Apps.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="unified-endpoints">Unified Endpoints<a href="#unified-endpoints" class="hash-link" aria-label="Direct link to Unified Endpoints" title="Direct link to Unified Endpoints">​</a></h2>
<p>The <strong>Unified Endpoints</strong> provide a consistent API interface that abstracts the provider-specific details of various AI services. Whether you are interfacing with an OpenAI-compatible service, an Azure OpenAI deployment, or an AWS Bedrock API, these endpoints enable you to use a standardized request/response format. This documentation explains the available endpoints, their purpose, and usage examples.</p>
<ol>
<li><strong>Single Entry Points</strong>: Instead of routing to different URLs for each provider, you call these “unified” endpoints with specific route parameters or path segments (e.g., <code>/completions</code>, <code>/chat/completions</code>, <code>/embeddings</code>, or <code>deployments/{deployment}/completions</code> in the case of Azure).</li>
<li><strong>Provider-Agnostic Handling</strong>: A common handler (e.g., <code>queryHandler(appState)</code>) receives each request and delegates it to the appropriate provider logic based on URL parameters like <code>providername</code> or <code>deployment</code>.</li>
<li><strong>Consistent Request/Response Shapes</strong>: All requests follow a uniform structure (for example, a JSON object with a <code>prompt</code>, <code>messages</code>, or <code>input</code> for embeddings). The service then translates it to each provider’s specific API format as needed.</li>
</ol>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="endpoint-breakdown">Endpoint Breakdown<a href="#endpoint-breakdown" class="hash-link" aria-label="Direct link to Endpoint Breakdown" title="Direct link to Endpoint Breakdown">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-openai-compatible-endpoints">1. OpenAI-Compatible Endpoints<a href="#1-openai-compatible-endpoints" class="hash-link" aria-label="Direct link to 1. OpenAI-Compatible Endpoints" title="Direct link to 1. OpenAI-Compatible Endpoints">​</a></h3>
<p>These endpoints mirror the standard OpenAI API methods. They allow you to perform common AI tasks such as generating text completions, handling chat-based requests, or producing embeddings.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="endpoints">Endpoints<a href="#endpoints" class="hash-link" aria-label="Direct link to Endpoints" title="Direct link to Endpoints">​</a></h4>
<ul>
<li>
<p><strong>POST <code>/{providername}/completions</code></strong><br>
<!-- -->Request text completions from the provider.<br>
<strong>Path Parameter:</strong></p>
<ul>
<li><code>providername</code>: Identifier for the OpenAI-compatible provider.</li>
</ul>
</li>
<li>
<p><strong>POST <code>/{providername}/chat/completions</code></strong><br>
<!-- -->Request chat-based completions (ideal for conversational interfaces).<br>
<strong>Path Parameter:</strong></p>
<ul>
<li><code>providername</code>: Identifier for the provider.</li>
</ul>
</li>
<li>
<p><strong>POST <code>/{providername}/embeddings</code></strong><br>
<!-- -->Generate embeddings for provided text data.<br>
<strong>Path Parameter:</strong></p>
<ul>
<li><code>providername</code>: Identifier for the provider.</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="example-usage">Example Usage<a href="#example-usage" class="hash-link" aria-label="Direct link to Example Usage" title="Direct link to Example Usage">​</a></h4>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">curl -X POST &quot;https://your-api-domain.com/openai/completions&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &quot;Content-Type: application/json&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -d &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;prompt&quot;: &quot;Once upon a time&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;max_tokens&quot;: 50</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Replace openai with the appropriate openai API compatible provider name like azure, mistral, deepseek etc. as required.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 2. Azure OpenAI API Endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">For providers using Azure’s deployment model, endpoints include an additional parameter for deployment management.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- **POST `/{providername}/deployments/{deployment}/completions`**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Request text completions from the provider.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  **Path Parameter:**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `providername`: The Azure OpenAI provider identifier.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `deployment`: The deployment ID configured in Azure.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- **POST `/{providername}/deployments/{deployment}/chat/completions`**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Request chat-based completions (ideal for conversational interfaces).  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  **Path Parameter:**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `providername`: The Azure OpenAI provider identifier.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `deployment`: The deployment ID configured in Azure.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- **POST `/{providername}/deployments/{deployment}/embeddings`**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Generate embeddings for provided text data.  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  **Path Parameter:**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `providername`: The Azure OpenAI provider identifier.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `deployment`: The deployment ID configured in Azure.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Example Usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">curl -X POST &quot;https://your-api-domain.com/azure/deployments/my-deployment/chat/completions&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &quot;Content-Type: application/json&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -d &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">           {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Tell me a story&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;max_tokens&quot;: 50</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 3. AWS Bedrock API Endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">For AWS Bedrock–style providers, the endpoints use a slightly different URL pattern to accommodate model versioning and extended routing.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- **POST `/model/{routename}/{apivariation}`**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Route requests to a specific model and API variation.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  **Path Parameter:**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `routename`: The model or route name (identifies a specific AWS Bedrock model).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `apivariation`:  A parameter to indicate the API variation (Invoke&quot;, &quot;Invoke-Stream&quot;, &quot;Invoke-With-Response-Stream&quot;, &quot;Converse&quot;, &quot;Converse-Stream) or version.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Example Usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">```bash</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">curl -X POST &quot;https://your-api-domain.com//model/anthropic.claude-3-sonnet-20240229-v1:0/invoke&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &quot;Content-Type: application/json&quot; \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -d &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;input&quot;: &quot;What is the capital of France?&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      }&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### 4. Query Endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">These endpoints allow direct querying of predefined routes, bypassing provider-specific names when a generic and customizable route configuration is desired.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#### Endpoints</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- **POST `/query/{routename}`**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Execute a query against a specific route.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  **Path Parameter:**  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  - `routename`: The route with one or more models based on the configured policies and route configurations and return back a response</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">###  Example Usage</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### REST API</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;Tabs&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;curl&quot; label=&quot;curl&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">First, create a route as shown in the [Create Route](../javelin-core/administration/createroute) section.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Once you have created a route, you can query it using the following curl command:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;bash&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`curl &#x27;https://api-dev.javelin.live/v1/query/your_route_name&#x27; \\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &#x27;Content-Type: application/json&#x27; \\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &#x27;Authorization: Bearer YOUR_OPENAI_API_KEY&#x27; \\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -H &#x27;x-api-key: YOUR_JAVELIN_API_KEY&#x27; \\</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  --data-raw &#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;SANFRANCISCO is located in?&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;temperature&quot;: 0.8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }&#x27;`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Make sure to replace `your_route_name`, `YOUR_OPENAI_API_KEY`, and `YOUR_JAVELIN_API_KEY` with your actual values.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;python&quot; label=&quot;Python Requests&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">First, create a route as shown in the [Create Route](../javelin-core/administration/createroute) section.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Once you have created a route, you can query it using Python requests:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`import requests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import dotenv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dotenv.load_dotenv()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_api_key = os.getenv(&#x27;JAVELIN_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openai_api_key = os.getenv(&#x27;OPENAI_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">route_name = &#x27;your_route_name&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">url = f&#x27;https://api-dev.javelin.live/v1/query/{route_name}&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">headers = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;Content-Type&#x27;: &#x27;application/json&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;Authorization&#x27;: f&#x27;Bearer {openai_api_key}&#x27;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &#x27;x-api-key&#x27;: javelin_api_key</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">data = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;SANFRANCISCO is located in?&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;temperature&quot;: 0.8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response = requests.post(url, headers=headers, json=data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if response.status_code == 200:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(response.json())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;Error: {response.status_code}, {response.text}&quot;)`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Make sure to replace `your_route_name` with your actual route name and set the `JAVELIN_API_KEY` and `OPENAI_API_KEY` environment variables.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/Tabs&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### Python</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;Tabs&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py1&quot; label=&quot;Javelin SDK&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`pip install javelin-sdk</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;Query Route with Javelin SDK&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`from javelin_sdk import JavelinClient, JavelinConfig, Route</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_api_key = os.getenv(&#x27;JAVELIN_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm_api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create Javelin configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config = JavelinConfig(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url=&quot;https://api-dev.javelin.live&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    javelin_api_key=javelin_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    llm_api_key=llm_api_key</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create Javelin client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = JavelinClient(config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Route name to get is {routename} e.g., sampleroute1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">query_data = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;messages&quot;: [ </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;role&quot;: &quot;system&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;content&quot;: &quot;Hello, you are a helpful scientific assistant.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;role&quot;: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;content&quot;: &quot;What is the chemical composition of sugar?&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;temperature&quot;: 0.8</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Now query the route, for async use &#x27;await client.aquery_route(&quot;sampleroute1&quot;, query_data)&#x27;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response = client.query_route(&quot;sampleroute1&quot;, query_data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(response.model_dump_json(indent=2))`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py2&quot; label=&quot;OpenAI&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`pip install openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;Query and Stream Responses with OpenAI&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`from openai import OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_api_key = os.environ[&#x27;JAVELIN_API_KEY&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm_api_key = os.environ[&quot;OPENAI_API_KEY&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">## Javelin Headers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define Javelin headers with the API key</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config = JavelinConfig(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  javelin_api_key=javelin_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define the Javelin route as a variable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_route = &quot;sampleroute1&quot;  # Define your universal route</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = JavelinClient(config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Register the OpenAI client with Javelin using the route name</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client.register_openai(openai_client, route_name=javelin_route)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Query the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># --- Call OpenAI Endpoints ---</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(&quot;OpenAI: 1 - Chat completions&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chat_completions = openai_client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model=&quot;gpt-3.5-turbo&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is machine learning?&quot;}],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(completion.model_dump_json(indent=2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Streaming Responses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stream = openai_client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages=[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Say this is a test&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model=&quot;gpt-4o&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stream=True,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for chunk in stream:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(chunk.choices[0].delta.content or &quot;&quot;, end=&quot;&quot;)`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py3&quot; label=&quot;Azure OpenAI&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;shell&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`pip install openai`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;Query and Stream Responses with AzureOpenAI&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`from openai import AzureOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Javelin Headers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_headers = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;x-api-key&quot;: javelin_api_key  # Javelin API key from admin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define the Javelin route as a variable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_route = &quot;sampleroute1&quot;  # Example route</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = JavelinClient(config) # Create Javelin Client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client.register_azureopenai(openai_client, route_name=javelin_route) # Register Azure OpenAI Client with Javelin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create Azure OpenAI Client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">openai_client = AzureOpenAI(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_version=&quot;2023-07-01-preview&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    azure_endpoint=&quot;https://javelinpreview.openai.azure.com&quot;, # Azure Endpoint</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    api_key=azure_openai_api_key</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">completion = openai_client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model=&quot;gpt-4&quot;,  # e.g. gpt-3.5-turbo</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages=[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;role&quot;: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;content&quot;: &quot;How do I output all files in a directory using Python?&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(completion.model_dump_json(indent=2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Streaming Responses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stream = openai_client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model=&quot;gpt-3.5-turbo&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages=[</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;Hello, you are a helpful scientific assistant.&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What is the chemical composition of sugar?&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    stream=True</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for chunk in stream:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  if chunk.choices:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(chunk.choices[0].delta.content or &quot;&quot;, end=&quot;&quot;)`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py4&quot; label=&quot;LangChain&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;shell&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`pip install langchain</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">pip install langchain-openai`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;LangChain with OpenAI Example&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`from langchain_openai import ChatOpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.prompts import ChatPromptTemplate</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_core.output_parsers import StrOutputParser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Retrieve API keys from environment variables</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_api_key = os.getenv(&#x27;JAVELIN_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm_api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model_choice = &quot;gpt-3.5-turbo&quot;  # For example, change to &quot;gpt-4&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define the Javelin route as a variable</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">route_name = &quot;sampleroute1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define Javelin headers with the API key</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_headers = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;x-api-key&quot;: javelin_api_key  # Javelin API key from admin</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm = ChatOpenAI(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    openai_api_key=openai_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    openai_api_base=&quot;https://api-dev.javelin.live/v1/openai&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    default_headers={</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;x-api-key&quot;: javelin_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;x-javelin-route&quot;: route_name,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;x-javelin-provider&quot;: &quot;https://api.openai.com/v1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;x-javelin-model&quot;:model_choice</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define a simple prompt template</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">prompt = ChatPromptTemplate.from_messages([</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    (&quot;system&quot;, &quot;You are a helpful assistant.&quot;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    (&quot;user&quot;, &quot;{input}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Use a simple output parser (string output)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">output_parser = StrOutputParser()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Create the processing chain (prompt -&gt; LLM -&gt; parser)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">chain = prompt | llm | output_parser</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def ask_question(question: str) -&gt; str:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return chain.invoke({&quot;input&quot;: question})</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Example usage:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">if __name__ == &quot;__main__&quot;:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    question = &quot;What is the chemical composition of water?&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    answer = ask_question(question)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(&quot;Answer:&quot;, answer)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py7&quot; label=&quot;OpenAI-Compatible Query Example&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;OpenAI-Compatible Model Adapters Example&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#This example demonstrates how Javelin uses OpenAI&#x27;s schema as a standardized interface for different LLM providers. </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#By adopting OpenAI&#x27;s widely-used request/response format, Javelin enables seamless integration with various LLM providers </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#(like Anthropic, Bedrock, Mistral, etc.) while maintaining a consistent API structure. This allows developers to use the </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">#same code pattern regardless of the underlying model provider, with Javelin handling the necessary translations and adaptations behind the scenes.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from javelin_sdk import JavelinClient, JavelinConfig</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from typing import Dict, Any</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Helper function to pretty print responses</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">def print_response(provider: str, response: Dict[str, Any]) -&gt; None:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;\n=== Response from {provider} ===&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(json.dumps(response, indent=2))</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Setup client configuration</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config = JavelinConfig(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url=&quot;https://api-dev.javelin.live&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    javelin_api_key=os.getenv(&#x27;JAVELIN_API_KEY&#x27;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    llm_api_key=os.getenv(&#x27;OPENAI_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = JavelinClient(config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Example messages in OpenAI format</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">messages = [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What are the three primary colors?&quot;}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 1. Query OpenAI route</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    openai_response = client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        route=&quot;openai_route&quot;,  # Route configured for OpenAI</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        temperature=0.7,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        max_tokens=150</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print_response(&quot;OpenAI&quot;, openai_response)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;OpenAI query failed: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">=== Response from OpenAI ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;id&quot;: &quot;chatcmpl-123abc&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;object&quot;: &quot;chat.completion&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;created&quot;: 1677858242,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;model&quot;: &quot;gpt-3.5-turbo&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;usage&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;prompt_tokens&quot;: 42,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;completion_tokens&quot;: 38,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;total_tokens&quot;: 80</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;choices&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;message&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;role&quot;: &quot;assistant&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;content&quot;: &quot;The three primary colors are red, blue, and yellow.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;finish_reason&quot;: &quot;stop&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;index&quot;: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># 2. Query Bedrock route (using same OpenAI format)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    bedrock_response = client.chat.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        route=&quot;bedrock_route&quot;,  # Route configured for Bedrock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        messages=messages,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        temperature=0.7,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        max_tokens=150</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print_response(&quot;Bedrock&quot;, bedrock_response)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;Bedrock query failed: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">=== Response from Bedrock ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;id&quot;: &quot;bedrock-123xyz&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;object&quot;: &quot;chat.completion&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;created&quot;: 1677858243,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;model&quot;: &quot;anthropic.claude-v2&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;usage&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;prompt_tokens&quot;: 42,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;completion_tokens&quot;: 41,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;total_tokens&quot;: 83</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;choices&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;message&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;role&quot;: &quot;assistant&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;content&quot;: &quot;The three primary colors are red, blue, and yellow. These colors cannot be created by mixing other colors together.&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;finish_reason&quot;: &quot;stop&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;index&quot;: 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Example using text completions with Llama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">try:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    llama_response = client.completions.create(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        route=&quot;bedrockllama&quot;,  # Route configured for Bedrock Llama</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        prompt=&quot;Write a haiku about programming:&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        max_tokens=50,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        temperature=0.7,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        top_p=0.9,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    )</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(&quot;=== Llama Text Completion Response ===&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    pretty_print(llama_response)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">except Exception as e:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(f&quot;Llama query failed: {str(e)}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">=== Llama Text Completion Response ===</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">{</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;id&quot;: &quot;bedrock-comp-123xyz&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;object&quot;: &quot;text_completion&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;created&quot;: 1677858244,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;model&quot;: &quot;meta.llama2-70b&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;choices&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;text&quot;: &quot;Code flows like water\\nBugs crawl through silent errors\\nDebugger saves all&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;index&quot;: 0,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      &quot;finish_reason&quot;: &quot;stop&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;usage&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;prompt_tokens&quot;: 6,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;completion_tokens&quot;: 15,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;total_tokens&quot;: 21</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&quot;&quot;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py5&quot; label=&quot;DSPy&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">**Introduction:** [DSPy: Goodbye Prompting, Hello Programming!](https://towardsdatascience.com/intro-to-dspy-goodbye-prompting-hello-programming-4ca1c6ce3eb9)  </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">**Documentation:** [DSPy Docs](https://dspy-docs.vercel.app/)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;shell&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`pip install dspy-ai`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;py&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;Using DSPY with Javelin&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`import dspy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from dsp import LM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import os</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import requests</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Assuming the environment variables are set correctly</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin_api_key = os.getenv(&#x27;JAVELIN_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm_api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">class Javelin(LM):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __init__(self, model, api_key):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.model = model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.api_key = api_key</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.provider = &quot;default&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.kwargs = { </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;temperature&quot;: 1.0, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;max_tokens&quot;: 500, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;top_p&quot;: 1.0, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;frequency_penalty&quot;: 0.0, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;presence_penalty&quot;: 0.0, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;stop&quot;: None, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;n&quot;: 1, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;logprobs&quot;: None, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;logit_bias&quot;: None,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;stream&quot;: False</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.base_url = &quot;https://api-dev.javelin.live/v1/query/your_route_name&quot; # Set Javelin&#x27;s API base URL for query</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.javelin_headers = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;Content-Type&quot;: &quot;application/json&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;Authorization&quot;: f&quot;Bearer { api_key }&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    &quot;x-api-key&quot;: javelin_api_key,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.history = []</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def basic_request(self, prompt: str, **kwargs):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        headers = self.javelin_headers</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        data = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            **kwargs,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;model&quot;: self.model,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response = requests.post(self.base_url, headers=headers, json=data)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response = response.json()</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        self.history.append({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;prompt&quot;: prompt,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;response&quot;: response,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            &quot;kwargs&quot;: kwargs,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        })</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        return response</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    def __call__(self, prompt, only_completed=True, return_sorted=False, **kwargs):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        response = self.request(prompt, **kwargs)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        if &#x27;choices&#x27; in response and len(response[&#x27;choices&#x27;]) &gt; 0:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            first_choice_content = response[&#x27;choices&#x27;][0][&#x27;message&#x27;][&#x27;content&#x27;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            completions = [first_choice_content]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return completions</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        else:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            return [&quot;No response found.&quot;]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">javelin = Javelin(model=&quot;gpt-4-1106-preview&quot;, api_key=llm_api_key)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dspy.configure(lm=javelin)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Define a module (ChainOfThought) and assign it a signature (return an answer, given a question).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">qa = dspy.ChainOfThought(&#x27;question -&gt; answer&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response = qa(question=&quot;You have 3 baskets. The first basket has twice as many apples as the second basket. The third basket has 3 fewer apples than the first basket. If you have a total of 27 apples, how many apples are in each basket?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(response)`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py6&quot; label=&quot;Bedrock&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;shell&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`pip install boto3`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;AWS Bedrock Integration Example - Boto3&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`import boto3</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">import json</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from javelin_sdk import (</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    JavelinClient,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    JavelinConfig,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Configure boto3 bedrock-runtime service client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bedrock_runtime_client = boto3.client(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    service_name=&quot;bedrock-runtime&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    region_name=&quot;us-east-1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Configure boto3 bedrock service client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">bedrock_client = boto3.client(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    service_name=&quot;bedrock&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    region_name=&quot;us-east-1&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Initialize Javelin Client</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">config = JavelinConfig(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    base_url=os.getenv(&#x27;JAVELIN_BASE_URL&#x27;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    javelin_api_key=os.getenv(&#x27;JAVELIN_API_KEY&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client = JavelinClient(config)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Passing bedrock_client is recommended for optimal error handling</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># and request management, though it remains optional.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client.register_bedrock(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  bedrock_runtime_client=bedrock_runtime_client, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  bedrock_client=bedrock_client, </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  route_name=&quot;bedrock&quot; # Universal route for the Amazon Bedrock models</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># Example using Claude model via Bedrock Runtime</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response = bedrock_runtime_client.invoke_model(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    modelId=&quot;anthropic.claude-v2:1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    body=json.dumps({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;anthropic_version&quot;: &quot;bedrock-2023-05-31&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;max_tokens&quot;: 100,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;messages&quot;: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;content&quot;: &quot;What is machine learning?&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                &quot;role&quot;: &quot;user&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        ]</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    contentType=&quot;application/json&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">response_body = json.loads(response[&quot;body&quot;].read())</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">print(f&quot;Invoke Response: {json.dumps(response_body, indent=2)}&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Learn more about how to setup Universal Bedrock routes to use this example [here](../javelin-core/administration/createbedrockroutes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;AWS Bedrock Integration Example - LangChain&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`# Example using Langchain </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">from langchain_community.llms.bedrock import Bedrock as BedrockLLM</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">llm = BedrockLLM(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    client=bedrock_runtime_client,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_id=&quot;anthropic.claude-v2:1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model_kwargs={</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;max_tokens_to_sample&quot;: 256,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        &quot;temperature&quot;: 0.7,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">stream_generator = llm.stream(&quot;What is machine learning?&quot;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for chunk in stream_generator:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    print(chunk, end=&#x27;&#x27;, flush=True)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Learn more about how to setup Universal Bedrock routes to use this example [here](../javelin-core/administration/createbedrockroutes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;py8&quot; label=&quot;...&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- [LlamaIndex](https://www.llamaindex.ai/open-source)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- [DataStax RAGStack](https://docs.datastax.com/en/ragstack/docs/index.html)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- [Instructor, Generating Structure from LLMs](https://jxnl.github.io/instructor/)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- [Microsoft Prompt flow](https://microsoft.github.io/promptflow/index.html#)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/Tabs&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">### JavaScript/TypeScript</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;Tabs&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;js1&quot; label=&quot;OpenAI&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`npm install openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;js&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;OpenAI API Integration Example&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`import OpenAI from &quot;openai&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const openai = new OpenAI({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  apiKey: process.env.OPENAI_API_KEY,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  baseURL: &quot;https://api-dev.javelin.live/v1/query&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  defaultHeaders: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;x-api-key&quot;: \`\${process.env.JAVELIN_API_KEY}\`,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    &quot;x-javelin-route&quot;: &quot;sample_route1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">});</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">async function main() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  const completion = await openai.chat.completions.create({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    messages: [{ role: &quot;system&quot;, content: &quot;You are a helpful assistant.&quot; }],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model: &quot;gpt-3.5-turbo&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  });</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  console.log(completion.choices[0]);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">main();`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;js2&quot; label=&quot;Langchain&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;python&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`npm install @langchain/openai</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;js&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;LangChain OpenAI Integration Example&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`import { ChatOpenAI } from &#x27;@langchain/openai&#x27;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const llm = new ChatOpenAI({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    openAIApiKey: process.env.OPENAI_API_KEY,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    configuration: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        basePath: &quot;https://api-dev.javelin.live/v1/query&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        defaultHeaders: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          &quot;x-api-key&quot;: \`\${process.env.JAVELIN_API_KEY}\`,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          &quot;x-javelin-route&quot;: &quot;sample_route1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">});</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">async function main() {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  const response = await llm.invoke(&quot;tell me a joke?&quot;);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  console.log(response);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">main();`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;js3&quot; label=&quot;Bedrock&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;CodeBlock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  language=&quot;js&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  title=&quot;AWS Bedrock Integration Example&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  showLineNumbers&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {`import { BedrockRuntimeClient, InvokeModelCommand, InvokeModelWithResponseStreamCommand } from &quot;@aws-sdk/client-bedrock-runtime&quot;;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const customHeaders = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &#x27;x-api-key&#x27;: JAVELIN_API_KEY</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const client = new BedrockRuntimeClient({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  region: AWS_REGION,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  // Use the javelin endpoint for bedrock</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  endpoint: JAVELIN_ENDPOINT,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  credentials: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    accessKeyId: AWS_ACCESS_KEY_ID,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    secretAccessKey: AWS_SECRET_ACCESS_KEY,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">});</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// Add custom headers via middleware</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">client.middlewareStack.add(</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  (next, context) =&gt; async (args) =&gt; {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args.request.headers = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...args.request.headers,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      ...customHeaders</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    };</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    return next(args);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    step: &quot;build&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  }</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">// Query the model</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const payload = {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  anthropic_version: &quot;bedrock-2023-05-31&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  max_tokens: 1000,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  messages: [</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      role: &quot;user&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      content: &quot;What is machine learning?&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    },</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  ],</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">};</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const command = new InvokeModelWithResponseStreamCommand({</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  contentType: &quot;application/json&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  body: JSON.stringify(payload),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;anthropic.claude-v2:1&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">});</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">const apiResponse = await client.send(command);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">for await (const item of apiResponse.body) {</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  console.log(item);</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">`}</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/CodeBlock&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Learn more about how to setup Bedrock routes to use these examples [here](../javelin-core/administration/createbedrockroutes).</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;TabItem value=&quot;js4&quot; label=&quot;...&quot;&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- [Vercel AI SDK](https://sdk.vercel.ai/docs) -&gt; [AI Integrations on Vercel](https://vercel.com/blog/ai-integrations)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- [Hugging Face ChatUI](https://github.com/huggingface/chat-ui) -&gt; [Running using a custom endpoint](https://github.com/huggingface/chat-ui?tab=readme-ov-file#running-your-own-models-using-a-custom-endpoint)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">We have worked on the integrations. Please contact: support@getjavelin.io if you would like to use this feature.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/TabItem&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">&lt;/Tabs&gt;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/getjavelin/documentation/tree/main/docs/javelin-core/integration.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/javelin-core/supported-llms"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Supported Language Models</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/javelin-webapp/threat-alerts/overview"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Overview</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#leveraging-the-javelin-platform" class="table-of-contents__link toc-highlight">Leveraging the Javelin Platform</a></li><li><a href="#unified-endpoints" class="table-of-contents__link toc-highlight">Unified Endpoints</a></li><li><a href="#endpoint-breakdown" class="table-of-contents__link toc-highlight">Endpoint Breakdown</a><ul><li><a href="#1-openai-compatible-endpoints" class="table-of-contents__link toc-highlight">1. OpenAI-Compatible Endpoints</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 Javelin.</div></div></div></footer></div>
</body>
</html>