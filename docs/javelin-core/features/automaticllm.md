# Automatic & Intelligent LLM Selection

Automatic LLM selection in Javelin intelligently chooses the most appropriate AI model for each request based on your specified criteria like cost, accuracy, or speed. This feature eliminates the complexity of manually selecting models by analyzing task requirements and dynamically routing requests to optimal providers. You'll learn to configure selection policies, set performance priorities, and leverage intelligent routing to maximize efficiency across diverse AI workloads.

## Dynamic Model Allocation

Javelin's advanced algorithm evaluates the requirements of a task and dynamically selects the most suitable LLM:

**Cost-Efficient:** For projects with strict budgets, Javelin can prioritize models that deliver good results at a lower cost.

**Precision-Focused:** If a task requires high accuracy, Javelin will allocate models known for their intricate analyses and detailed outputs.

**Speed-Centric:** For applications needing rapid feedback, Javelin opts for models streamlined for quick processing without significantly compromising on accuracy.

## Benefits

By automating model selection, Javelin removes the complexities involved in manual LLM selection:

**No Guesswork:** Developers need not spend time assessing which LLM is optimal for each task. Javelin’s intelligence handles it.

**Seamless Integration:** Users interact with Javelin’s interface, receiving results from the best LLM for the task without even realizing the complex selection process happening behind the scenes.

**Dynamic Adjustments:** As tasks evolve and demands change, Javelin can dynamically adjust its model selection criteria, ensuring sustained optimal performance.

**User Preferences:** If a user has a specific preference or requirement, they can guide Javelin’s selection process by defining certain parameters or setting priorities.

Please contact: support@getjavelin.io if you would like to use this feature. 