"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[496],{8550:(e,a,i)=>{i.r(a),i.d(a,{assets:()=>r,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>n,toc:()=>c});let n=JSON.parse('{"id":"javelin-core/features/loadbalancing","title":"Load Balancing","description":"Load balancing in Javelin distributes traffic across multiple AI models and providers to optimize performance, cost, and reliability. This feature allows you to implement sophisticated traffic shaping strategies, set up fallback mechanisms, and distribute load across multiple API credentials. You\'ll learn to configure load balancing for traffic optimization, cost management, and high availability scenarios.","source":"@site/docs/javelin-core/features/loadbalancing.md","sourceDirName":"javelin-core/features","slug":"/javelin-core/features/loadbalancing","permalink":"/javelin-core/features/loadbalancing","draft":false,"unlisted":false,"editUrl":"https://github.com/getjavelin/documentation/tree/main/docs/javelin-core/features/loadbalancing.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Fallback Routing","permalink":"/javelin-core/fallbackrouting/overview"},"next":{"title":"Javelin Proxy","permalink":"/javelin-core/features/javelinproxy"}}');var t=i(74848),l=i(28453);let o={},s="Load Balancing",r={},c=[{value:"Use Cases",id:"use-cases",level:2},{value:"Traffic Load Shaping",id:"traffic-load-shaping",level:3},{value:"LLM Fallback",id:"llm-fallback",level:3},{value:"Credential Multiplexing",id:"credential-multiplexing",level:3}];function d(e){let a={a:"a",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(a.header,{children:(0,t.jsx)(a.h1,{id:"load-balancing",children:"Load Balancing"})}),"\n",(0,t.jsx)(a.p,{children:"Load balancing in Javelin distributes traffic across multiple AI models and providers to optimize performance, cost, and reliability. This feature allows you to implement sophisticated traffic shaping strategies, set up fallback mechanisms, and distribute load across multiple API credentials. You'll learn to configure load balancing for traffic optimization, cost management, and high availability scenarios."}),"\n",(0,t.jsx)(a.h2,{id:"use-cases",children:"Use Cases"}),"\n",(0,t.jsx)(a.h3,{id:"traffic-load-shaping",children:"Traffic Load Shaping"}),"\n",(0,t.jsx)(a.p,{children:"Organizations may want to strike a balance between inference accuracy, cost and latency by setting up a load shaping mix that shapes traffic towards multiple LLMs."}),"\n",(0,t.jsx)(a.p,{children:"For instance, an example traffic shape could be setup for using OpenAI GPT3.5 Turbo for 70% of the traffic and OpenAI GPT4 for 30% of the traffic."}),"\n",(0,t.jsx)(a.h3,{id:"llm-fallback",children:"LLM Fallback"}),"\n",(0,t.jsx)(a.p,{children:"One way to manage inference costs is to setup LLM fallbacks when specific routes have exhausted their budgets."}),"\n",(0,t.jsx)(a.p,{children:"For instance, the route may be defined to use OpenAI GPT3.5 Turbo with a Google Gemini fallback when the cost or policy budgets are exceeded."}),"\n",(0,t.jsx)(a.h3,{id:"credential-multiplexing",children:"Credential Multiplexing"}),"\n",(0,t.jsx)(a.p,{children:"Many model providers enforce rate limiting on each of their credentials provisioned. As Application inference needs continually expand, they find that it may be beneficial to spread their load evenly across multiple credentials (or keys)."}),"\n",(0,t.jsx)(a.p,{children:"For instance, the Application may choose to spread an anticipated load of 100 queries/second across 10 credential keys each with 10 queries/sec towards a specific model."}),"\n",(0,t.jsxs)(a.p,{children:["Please contact: ",(0,t.jsx)(a.a,{href:"mailto:support@getjavelin.io",children:"support@getjavelin.io"})," if you would like to use this feature."]})]})}function u(e={}){let{wrapper:a}={...(0,l.R)(),...e.components};return a?(0,t.jsx)(a,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},28453:(e,a,i)=>{i.d(a,{R:()=>o,x:()=>s});var n=i(96540);let t={},l=n.createContext(t);function o(e){let a=n.useContext(l);return n.useMemo(function(){return"function"==typeof e?e(a):{...a,...e}},[a,e])}function s(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),n.createElement(l.Provider,{value:a},e.children)}}}]);