"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[1780],{66593:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"javelin-core/features/automaticllm","title":"Automatic & Intelligent LLM Selection","description":"The digital landscape is vast and varied, necessitating AI solutions that can efficiently cater to diverse needs.","source":"@site/docs/javelin-core/features/automaticllm.md","sourceDirName":"javelin-core/features","slug":"/javelin-core/features/automaticllm","permalink":"/docs/javelin-core/features/automaticllm","draft":false,"unlisted":false,"editUrl":"https://github.com/getjavelin/documentation/tree/main/docs/javelin-core/features/automaticllm.md","tags":[],"version":"current","frontMatter":{},"sidebar":"someSidebar","previous":{"title":"Semantic Caching","permalink":"/docs/javelin-core/features/caching"},"next":{"title":"Archiving","permalink":"/docs/javelin-core/features/auditarchive"}}');var s=t(74848),a=t(28453);const r={},o="Automatic & Intelligent LLM Selection",c={},l=[{value:"Dynamic Model Allocation",id:"dynamic-model-allocation",level:2},{value:"Benefits",id:"benefits",level:2}];function d(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"automatic--intelligent-llm-selection",children:"Automatic & Intelligent LLM Selection"})}),"\n",(0,s.jsx)(n.p,{children:"The digital landscape is vast and varied, necessitating AI solutions that can efficiently cater to diverse needs."}),"\n",(0,s.jsx)(n.p,{children:"With the extensive range of Large Language Models (LLMs) available, the question often arises:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Which model is best for a particular task?"})}),"\n",(0,s.jsx)(n.p,{children:"Javelin provides an answer by automating this choice, ensuring optimal performance based on the desired parameters."}),"\n",(0,s.jsx)(n.h2,{id:"dynamic-model-allocation",children:"Dynamic Model Allocation"}),"\n",(0,s.jsx)(n.p,{children:"Javelin's advanced algorithm evaluates the requirements of a task and dynamically selects the most suitable LLM:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Cost-Efficient:"})," For projects with strict budgets, Javelin can prioritize models that deliver good results at a lower cost."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Precision-Focused:"})," If a task requires high accuracy, Javelin will allocate models known for their intricate analyses and detailed outputs."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Speed-Centric:"})," For applications needing rapid feedback, Javelin opts for models streamlined for quick processing without significantly compromising on accuracy."]}),"\n",(0,s.jsx)(n.h2,{id:"benefits",children:"Benefits"}),"\n",(0,s.jsx)(n.p,{children:"By automating model selection, Javelin removes the complexities involved in manual LLM selection:"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"No Guesswork:"})," Developers need not spend time assessing which LLM is optimal for each task. Javelin\u2019s intelligence handles it."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Seamless Integration:"})," Users interact with Javelin\u2019s interface, receiving results from the best LLM for the task without even realizing the complex selection process happening behind the scenes."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Dynamic Adjustments:"})," As tasks evolve and demands change, Javelin can dynamically adjust its model selection criteria, ensuring sustained optimal performance."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"User Preferences:"})," If a user has a specific preference or requirement, they can guide Javelin\u2019s selection process by defining certain parameters or setting priorities."]}),"\n",(0,s.jsxs)(n.p,{children:["Please contact: ",(0,s.jsx)(n.a,{href:"mailto:support@getjavelin.io",children:"support@getjavelin.io"})," if you would like to use this feature."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(96540);const s={},a=i.createContext(s);function r(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);