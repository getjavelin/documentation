"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[9717],{5680:(e,n,t)=>{t.d(n,{xA:()=>s,yg:()=>h});var r=t(6540);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function p(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)t=i[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var c=r.createContext({}),l=function(e){var n=r.useContext(c),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},s=function(e){var n=l(e.components);return r.createElement(c.Provider,{value:n},e.children)},u="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},y=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,i=e.originalType,c=e.parentName,s=p(e,["components","mdxType","originalType","parentName"]),u=l(t),y=a,h=u["".concat(c,".").concat(y)]||u[y]||m[y]||i;return t?r.createElement(h,o(o({ref:n},s),{},{components:t})):r.createElement(h,o({ref:n},s))}));function h(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var i=t.length,o=new Array(i);o[0]=y;var p={};for(var c in n)hasOwnProperty.call(n,c)&&(p[c]=n[c]);p.originalType=e,p[u]="string"==typeof e?e:a,o[1]=p;for(var l=2;l<i;l++)o[l]=t[l];return r.createElement.apply(null,o)}return r.createElement.apply(null,t)}y.displayName="MDXCreateElement"},4166:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>p,toc:()=>l});var r=t(8168),a=(t(6540),t(5680));const i={},o="Quickstart",p={unversionedId:"javelin-langchain-python/quickstart",id:"javelin-langchain-python/quickstart",title:"Quickstart",description:"With your LangChain environment, you can use Javelin by changing the API base and adding Javelin headers",source:"@site/docs/javelin-langchain-python/quickstart.md",sourceDirName:"javelin-langchain-python",slug:"/javelin-langchain-python/quickstart",permalink:"/docs/javelin-langchain-python/quickstart",draft:!1,editUrl:"https://github.com/getjavelin/documentation/tree/main/docs/javelin-langchain-python/quickstart.md",tags:[],version:"current",frontMatter:{},sidebar:"someSidebar",previous:{title:"Applications",permalink:"/docs/javelin-core/integration"},next:{title:"Chain Integration",permalink:"/docs/javelin-langchain-python/chain"}},c={},l=[],s={toc:l},u="wrapper";function m(e){let{components:n,...t}=e;return(0,a.yg)(u,(0,r.A)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"quickstart"},"Quickstart"),(0,a.yg)("p",null,"With your LangChain environment, you can use Javelin by changing the API base and adding Javelin headers"),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-python"},'from openai import OpenAI\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\nimport os\n\njavelin_api_key = os.getenv(\'JAVELIN_API_KEY\')\nllm_api_key = os.getenv("OPENAI_API_KEY")\njavelin_headers = {\n                    "x-api-key": javelin_api_key,      # Javelin API key from admin\n                    "x-javelin-route": "sample_route1" # Javelin route to use\n                  }\n\nllm = ChatOpenAI(\n    openai_api_base="https://api.javelin.live/v1/query",\n    openai_api_key=llm_api_key,\n    model_kwargs={\n      "extra_headers": javelin_headers\n    },\n)\n\nprompt = ChatPromptTemplate.from_messages([\n    ("system", "Hello, you are a helpful scientific assistant."),\n    ("user", "{input}")\n])\n\noutput_parser = StrOutputParser()\n\nchain = prompt | llm | output_parser\n\nprint(chain.invoke({"input": "What is the chemical composition of sugar?"}))\n')))}m.isMDXComponent=!0}}]);