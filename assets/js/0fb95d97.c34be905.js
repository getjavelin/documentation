"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[9717],{36205:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>p,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>h});var t=a(74848),i=a(28453),o=a(21432);const r={},p="Quickstart",s={id:"javelin-langchain-python/quickstart",title:"Quickstart",description:"With your LangChain environment, you can use Javelin by changing the API base and adding Javelin headers",source:"@site/docs/javelin-langchain-python/quickstart.md",sourceDirName:"javelin-langchain-python",slug:"/javelin-langchain-python/quickstart",permalink:"/docs/javelin-langchain-python/quickstart",draft:!1,unlisted:!1,editUrl:"https://github.com/getjavelin/documentation/tree/main/docs/javelin-langchain-python/quickstart.md",tags:[],version:"current",frontMatter:{}},l={},h=[];function c(n){const e={h1:"h1",header:"header",p:"p",...(0,i.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"quickstart",children:"Quickstart"})}),"\n",(0,t.jsx)(e.p,{children:"With your LangChain environment, you can use Javelin by changing the API base and adding Javelin headers"}),"\n",(0,t.jsx)(o.A,{language:"python",children:"pip install langchain\npip install langchain-openai\n"}),"\n",(0,t.jsx)(o.A,{language:"python",title:"ChatOpenAI Configuration Example",showLineNumbers:!0,children:'# Code snippet\n\nllm = ChatOpenAI(\n    openai_api_base="https://api-dev.javelin.live/v1/query",\n    openai_api_key=openai_api_key, # OpenAI API key\n    model_kwargs={\n      "extra_headers":{\n        "x-api-key": f"{JAVELIN_API_KEY}", # Javelin API key from admin\n        "x-javelin-route": "sample_route1" # Javelin route to use\n      }\n    },\n    openai_api_base="https://api-dev.javelin.live/v1/query",\n)\n'}),"\n",(0,t.jsx)(e.p,{children:"Below is a sample code to use Javelin with LangChain:"}),"\n",(0,t.jsx)(o.A,{language:"python",title:"Simple Chat Prompt Example",showLineNumbers:!0,children:'# Example of a simple chat prompt\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nimport openai, os\n\nprompt = ChatPromptTemplate.from_template("tell me a short joke about {topic}")\n\n# model = ChatOpenAI(model="gpt-4")\nmodel = ChatOpenAI(\n    openai_api_key=os.getenv("OPENAI_API_KEY"),\n    openai_api_base="https://api-dev.javelin.live/v1/query",\n    model_kwargs={\n        "extra_headers":{\n        "x-api-key": f"{os.getenv(\'JAVELIN_API_KEY\')}",\n        "x-javelin-route": "sample_route1", # Javelin route to use\n        }\n    }\n)\n\noutput_parser = StrOutputParser()\n\nchain = prompt | model | output_parser\n\nresponse = chain.invoke({"topic": "ice cream"})\nprint(response)\n'})]})}function u(n={}){const{wrapper:e}={...(0,i.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(c,{...n})}):c(n)}}}]);