"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[1780],{5680:(e,t,n)=>{n.d(t,{xA:()=>u,yg:()=>g});var a=n(6540);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},p="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(n),d=r,g=p["".concat(s,".").concat(d)]||p[d]||m[d]||i;return n?a.createElement(g,o(o({ref:t},u),{},{components:n})):a.createElement(g,o({ref:t},u))}));function g(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:r,o[1]=l;for(var c=2;c<i;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},7616:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=n(8168),r=(n(6540),n(5680));const i={},o="Automatic & Intelligent LLM Selection",l={unversionedId:"javelin-core/features/automaticllm",id:"javelin-core/features/automaticllm",title:"Automatic & Intelligent LLM Selection",description:"The digital landscape is vast and varied, necessitating AI solutions that can efficiently cater to diverse needs.",source:"@site/docs/javelin-core/features/automaticllm.md",sourceDirName:"javelin-core/features",slug:"/javelin-core/features/automaticllm",permalink:"/docs/javelin-core/features/automaticllm",draft:!1,editUrl:"https://github.com/getjavelin/documentation/tree/main/docs/javelin-core/features/automaticllm.md",tags:[],version:"current",frontMatter:{},sidebar:"someSidebar",previous:{title:"Semantic Caching",permalink:"/docs/javelin-core/features/caching"},next:{title:"Archiving",permalink:"/docs/javelin-core/features/auditarchive"}},s={},c=[{value:"Dynamic Model Allocation",id:"dynamic-model-allocation",level:2},{value:"Benefits",id:"benefits",level:2}],u={toc:c},p="wrapper";function m(e){let{components:t,...n}=e;return(0,r.yg)(p,(0,a.A)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"automatic--intelligent-llm-selection"},"Automatic & Intelligent LLM Selection"),(0,r.yg)("p",null,"The digital landscape is vast and varied, necessitating AI solutions that can efficiently cater to diverse needs. "),(0,r.yg)("p",null,"With the extensive range of Large Language Models (LLMs) available, the question often arises: "),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Which model is best for a particular task?")," "),(0,r.yg)("p",null,"Javelin provides an answer by automating this choice, ensuring optimal performance based on the desired parameters."),(0,r.yg)("h2",{id:"dynamic-model-allocation"},"Dynamic Model Allocation"),(0,r.yg)("p",null,"Javelin's advanced algorithm evaluates the requirements of a task and dynamically selects the most suitable LLM:"),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Cost-Efficient:")," For projects with strict budgets, Javelin can prioritize models that deliver good results at a lower cost."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Precision-Focused:")," If a task requires high accuracy, Javelin will allocate models known for their intricate analyses and detailed outputs."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Speed-Centric:")," For applications needing rapid feedback, Javelin opts for models streamlined for quick processing without significantly compromising on accuracy."),(0,r.yg)("h2",{id:"benefits"},"Benefits"),(0,r.yg)("p",null,"By automating model selection, Javelin removes the complexities involved in manual LLM selection:"),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"No Guesswork:")," Developers need not spend time assessing which LLM is optimal for each task. Javelin\u2019s intelligence handles it."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Seamless Integration:")," Users interact with Javelin\u2019s interface, receiving results from the best LLM for the task without even realizing the complex selection process happening behind the scenes."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"Dynamic Adjustments:")," As tasks evolve and demands change, Javelin can dynamically adjust its model selection criteria, ensuring sustained optimal performance."),(0,r.yg)("p",null,(0,r.yg)("strong",{parentName:"p"},"User Preferences:")," If a user has a specific preference or requirement, they can guide Javelin\u2019s selection process by defining certain parameters or setting priorities."),(0,r.yg)("p",null,"Please contact: ",(0,r.yg)("a",{parentName:"p",href:"mailto:support@getjavelin.io"},"support@getjavelin.io")," if you would like to use this feature."))}m.isMDXComponent=!0}}]);