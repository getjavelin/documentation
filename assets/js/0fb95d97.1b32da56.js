"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[9717],{76303:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>p,metadata:()=>t,toc:()=>h});const t=JSON.parse('{"id":"javelin-langchain-python/quickstart","title":"Quickstart","description":"With your LangChain environment, you can use Javelin by changing the API base and adding Javelin headers","source":"@site/docs/javelin-langchain-python/quickstart.md","sourceDirName":"javelin-langchain-python","slug":"/javelin-langchain-python/quickstart","permalink":"/docs/javelin-langchain-python/quickstart","draft":false,"unlisted":false,"editUrl":"https://github.com/getjavelin/documentation/tree/main/docs/javelin-langchain-python/quickstart.md","tags":[],"version":"current","frontMatter":{}}');var i=a(74848),o=a(28453),r=a(76430);const p={},s="Quickstart",l={},h=[];function c(n){const e={h1:"h1",header:"header",p:"p",...(0,o.R)(),...n.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(e.header,{children:(0,i.jsx)(e.h1,{id:"quickstart",children:"Quickstart"})}),"\n",(0,i.jsx)(e.p,{children:"With your LangChain environment, you can use Javelin by changing the API base and adding Javelin headers"}),"\n",(0,i.jsx)(r.A,{language:"python",children:"pip install langchain\npip install langchain-openai\n"}),"\n",(0,i.jsx)(r.A,{language:"python",title:"ChatOpenAI Configuration Example",showLineNumbers:!0,children:'# Code snippet\n\nllm = ChatOpenAI(\n    openai_api_base="https://api-dev.javelin.live/v1/query",\n    openai_api_key=openai_api_key, # OpenAI API key\n    model_kwargs={\n      "extra_headers":{\n        "x-api-key": f"{JAVELIN_API_KEY}", # Javelin API key from admin\n        "x-javelin-route": "sample_route1" # Javelin route to use\n      }\n    },\n    openai_api_base="https://api-dev.javelin.live/v1/query",\n)\n'}),"\n",(0,i.jsx)(e.p,{children:"Below is a sample code to use Javelin with LangChain:"}),"\n",(0,i.jsx)(r.A,{language:"python",title:"Simple Chat Prompt Example",showLineNumbers:!0,children:'# Example of a simple chat prompt\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_openai import ChatOpenAI\nimport openai, os\n\nprompt = ChatPromptTemplate.from_template("tell me a short joke about {topic}")\n\n# model = ChatOpenAI(model="gpt-4")\nmodel = ChatOpenAI(\n    openai_api_key=os.getenv("OPENAI_API_KEY"),\n    openai_api_base="https://api-dev.javelin.live/v1/query",\n    model_kwargs={\n        "extra_headers":{\n        "x-api-key": f"{os.getenv(\'JAVELIN_API_KEY\')}",\n        "x-javelin-route": "sample_route1", # Javelin route to use\n        }\n    }\n)\n\noutput_parser = StrOutputParser()\n\nchain = prompt | model | output_parser\n\nresponse = chain.invoke({"topic": "ice cream"})\nprint(response)\n'})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,i.jsx)(e,{...n,children:(0,i.jsx)(c,{...n})}):c(n)}}}]);