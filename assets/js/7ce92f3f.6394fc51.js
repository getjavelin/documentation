"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[4872],{73790:(e,s,t)=>{t.r(s),t.d(s,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>n,toc:()=>l});const n=JSON.parse('{"id":"javelin-core/supported-llms","title":"Supported Language Models","description":"Javelin is committed to integrating and supporting the most popular models in the industry. From the groundbreaking innovations of OpenAI and Azure OpenAI to the dynamic platforms like HuggingFace and Anthropic, Javelin ensures seamless interfacing with these models.","source":"@site/docs/javelin-core/supported-llms.md","sourceDirName":"javelin-core","slug":"/javelin-core/supported-llms","permalink":"/docs/javelin-core/supported-llms","draft":false,"unlisted":false,"editUrl":"https://github.com/getjavelin/documentation/tree/main/docs/javelin-core/supported-llms.md","tags":[],"version":"current","frontMatter":{},"sidebar":"someSidebar","previous":{"title":"Overview","permalink":"/docs/javelin-core/overview"},"next":{"title":"Applications","permalink":"/docs/javelin-core/integration"}}');var d=t(74848),r=t(28453);const i={},o="Supported Language Models",c={},l=[{value:"Supported Model Providers",id:"supported-model-providers",level:2}];function a(e){const s={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,r.R)(),...e.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(s.header,{children:(0,d.jsx)(s.h1,{id:"supported-language-models",children:"Supported Language Models"})}),"\n",(0,d.jsx)(s.p,{children:"Javelin is committed to integrating and supporting the most popular models in the industry. From the groundbreaking innovations of OpenAI and Azure OpenAI to the dynamic platforms like HuggingFace and Anthropic, Javelin ensures seamless interfacing with these models."}),"\n",(0,d.jsx)(s.p,{children:"Our platform's adaptability allows users to leverage the unique strengths of each model, ensuring optimal results for diverse applications. Javelin Gateway harmoniously brings together the world of popular LLMs, simplifying and amplifying their capabilities for our users."}),"\n",(0,d.jsx)(s.h2,{id:"supported-model-providers",children:"Supported Model Providers"}),"\n",(0,d.jsx)(s.p,{children:"We are always adding support for new models, supported models include those from:"}),"\n",(0,d.jsxs)(s.table,{children:[(0,d.jsx)(s.thead,{children:(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.th,{children:"Models"}),(0,d.jsx)(s.th,{children:"Base URL"}),(0,d.jsx)(s.th,{children:"Endpoints (text & embeddings)"})]})}),(0,d.jsxs)(s.tbody,{children:[(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models",children:"Azure OpenAI"})}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.code,{children:"https://<your-resource-name>.openai.azure.com"})}),(0,d.jsxs)(s.td,{children:["- ",(0,d.jsx)(s.code,{children:"/openai/deployments/{deployment-name}/completions"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/openai/deployments/{deployment-name}/chat/completions"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/openai/deployments/{deployment-name}/embeddings"})]})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://platform.openai.com/docs/models",children:"OpenAI"})}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.code,{children:"https://api.openai.com/v1"})}),(0,d.jsxs)(s.td,{children:["- ",(0,d.jsx)(s.code,{children:"/completions"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/chat/completions"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/embeddings"}),(0,d.jsx)("br",{})]})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://aws.amazon.com/bedrock",children:"Amazon Bedrock"})}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.code,{children:"https://bedrock.<region>.amazonaws.com"})}),(0,d.jsxs)(s.td,{children:["- ",(0,d.jsx)(s.code,{children:"/model/{modelId}/invoke"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/model/{modelId}/invoke-with-response-stream"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/model/{modelId}/converse"}),(0,d.jsx)("br",{}),"- ",(0,d.jsx)(s.code,{children:"/model/{modelId}/converse-stream"}),(0,d.jsx)("br",{})]})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://ai.google.dev/models",children:"Google Gemini"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://huggingface.co/models",children:"HuggingFace"})}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.code,{children:"https://api-inference.huggingface.co"})}),(0,d.jsxs)(s.td,{children:["Create an endpoint following the instructions here ",(0,d.jsx)(s.a,{href:"https://huggingface.co/docs/inference-endpoints/guides/create_endpoint",children:"https://huggingface.co/docs/inference-endpoints/guides/create_endpoint"})]})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://build.nvidia.com/explore/discover",children:"NVIDIA"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://docs.nvidia.com/nemo/guardrails/user_guides/llm/nvidia_ai_endpoints/index.html",children:"NVIDIA AI Endpoints"})})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://llama.meta.com/",children:"Llama"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://docs.anthropic.com/claude/docs/models-overview",children:"Anthropic"})}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.code,{children:"https://api.anthropic.com/v1"})}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://docs.mistral.ai/guides/model-selection/",children:"Mistral"})}),(0,d.jsx)(s.td,{children:(0,d.jsx)(s.code,{children:"https://api.mistral.ai/v1"})}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://inflection.ai/inflection-2-5",children:"Inflection"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://docs.perplexity.ai/docs/model-cards",children:"Perplexity"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://cohere.com/",children:"Cohere"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://www.anyscale.com/endpoints",children:"AnyScale"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.a,{href:"https://www.together.ai/",children:"TogetherAI"})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]}),(0,d.jsxs)(s.tr,{children:[(0,d.jsx)(s.td,{children:(0,d.jsx)(s.strong,{children:"and more..."})}),(0,d.jsx)(s.td,{}),(0,d.jsx)(s.td,{})]})]})]})]})}function h(e={}){const{wrapper:s}={...(0,r.R)(),...e.components};return s?(0,d.jsx)(s,{...e,children:(0,d.jsx)(a,{...e})}):a(e)}},28453:(e,s,t)=>{t.d(s,{R:()=>i,x:()=>o});var n=t(96540);const d={},r=n.createContext(d);function i(e){const s=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(s):{...s,...e}}),[s,e])}function o(e){let s;return s=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:i(e.components),n.createElement(r.Provider,{value:s},e.children)}}}]);